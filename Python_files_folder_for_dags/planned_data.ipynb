{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c635949",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"Planned Data Patern\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d134a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/plan/\"\n",
    "\n",
    "headers = {\n",
    "    \"DB-Client-Id\": \"7b61ee043a945260d2fefbcf867ee8c0\",\n",
    "    \"DB-Api-Key\": \"8f4ad462350ee13f932a3aa4a42663b8\",\n",
    "    \"accept\": \"application/xml\"\n",
    "}\n",
    "\n",
    "df = spark.read.parquet(\"/stations.parquet\") \n",
    "eva_df = df.select(\"eva\").distinct()\n",
    "station_number = [row[\"eva\"] for row in eva_df.collect()]\n",
    "\n",
    "for station in station_number:\n",
    "\n",
    "    dt_plan = datetime.today().strftime('%y%m%d/%H')\n",
    "    response = requests.get(f'{url}/{station}/{dt_plan}', headers=headers)\n",
    "    folder = '/opt/airflow/plan_data_folder'\n",
    "    dt = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    with open(f'{folder}/plan_d-{station}_{dt}.xml', 'wb') as foutput:\n",
    "        foutput.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
